# bike-data-lakehouse
End-to-end Databricks Lakehouse project using the Medallion Architecture (Bronze, Silver, Gold) with CSV ingestion and Unity Catalog governance.
## **Project Overview**
This project demonstrates how to build a production-style Data Lakehouse using Databricks and the Medallion Architecture (Bronze, Silver, Gold).
Raw data is ingested, cleaned, transformed, and modeled into analytics-ready datasets using PySpark and Delta Lake, following best practices used in real-world data engineering projects.
## **Architecture Overview**
â€¢ **Bronze Layer:** Raw data ingestion with minimal transformations  
â€¢ **Silver Layer:** Data cleansing, standardization, validation, and deduplication  
â€¢ **Gold Layer:** Business-ready dimensional and fact tables optimized for analytics and reporting
## ðŸ§° Tech Stack & Tools
â€¢ **Cloud Platform:** Databricks (Community / Standard Edition)  
â€¢ **Programming Languages:** Python (PySpark), SQL  
â€¢ **Data Storage Format:** Delta Lake (open-source storage layer)  
â€¢ **Orchestration:** Databricks Workflows (Jobs)  
â€¢ **Version Control:** GitHub (Databricks Git integration)



